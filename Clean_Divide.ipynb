{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJJf1kD8Hn_I"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "path_list = [\n",
        "    '/home/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Tuesday-WorkingHours.pcap_ISCX.csv',\n",
        "    '/home/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Wednesday-workingHours.pcap_ISCX.csv',\n",
        "    '/home/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
        "    '/homme/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
        "    '/home/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
        "    '/home/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
        "    '/home/keshav/Desktop/CIC AWS 2018/cicids 2017/cicids data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n",
        "]\n",
        "\n",
        "\n",
        "def reduce_data(data):\n",
        "    label = list(data[' Label'].unique())\n",
        "    data_count = data[' Label'].value_counts()\n",
        "    attack_count = 0\n",
        "    for count in data_count[1:]:\n",
        "        attack_count = attack_count + count\n",
        "\n",
        "    data1 = pd.DataFrame()\n",
        "    for name in label:\n",
        "        if name is label[0]:\n",
        "            temp_data = data[data[' Label'] == name]\n",
        "            temp_data = temp_data[:attack_count * 2]\n",
        "            data1 = pd.concat([data1, temp_data], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "            temp_data = data[data[' Label'] == name]\n",
        "            data1 = pd.concat([data1, temp_data], ignore_index=True)\n",
        "\n",
        "    return data1\n",
        "\n",
        "\n",
        "def merge_data():\n",
        "    data = pd.DataFrame()\n",
        "    for path in path_list:\n",
        "        # print(path)\n",
        "        if path == path_list[1]:\n",
        "            file = open('ddos_data.txt', 'rb')\n",
        "            temp_data = pickle.load(file)\n",
        "            reduced_data = reduce_data(temp_data)\n",
        "            data = pd.concat([data, reduced_data], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "            temp_data = pd.read_csv(path)\n",
        "            reduced_data = reduce_data(temp_data)\n",
        "            data = pd.concat([data, reduced_data], ignore_index=True)\n",
        "\n",
        "        data = shuffle(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_data(data):\n",
        "    column_list = data.columns\n",
        "    info = data[column_list[-1]].value_counts()\n",
        "    data_info = list(data[column_list[-1]].unique())\n",
        "    label_length = len(data_info)\n",
        "    attack_labels = data_info[1:label_length]\n",
        "\n",
        "    # Appending malicious data to the dataframe.\n",
        "    bruteforce_data = pd.DataFrame()\n",
        "    for label in attack_labels:\n",
        "        temp_data = data[data[column_list[-1]] == label]\n",
        "        bruteforce_data = pd.concat([bruteforce_data, temp_data],\n",
        "                                    ignore_index=True)\n",
        "\n",
        "    # Appending benign data to the dataframe.\n",
        "    benign_data_all = data[data[column_list[-1]] == data_info[0]]\n",
        "    benign_data = benign_data_all[:len(bruteforce_data)]\n",
        "    bruteforce_data = pd.concat([bruteforce_data, benign_data],\n",
        "                                ignore_index=True)\n",
        "\n",
        "    # Shuffling the dataset.\n",
        "    bruteforce_data = shuffle(bruteforce_data)\n",
        "    bruteforce_data.index = np.arange(0, len(bruteforce_data))\n",
        "\n",
        "    # Dropping the destination host column.\n",
        "    bruteforce_data = bruteforce_data.drop([column_list[0]], axis=1)\n",
        "\n",
        "    # Splitting the dataset into X and Y.\n",
        "    y_bruteforce = bruteforce_data[' Label']\n",
        "    x_bruteforce = bruteforce_data.drop([' Label'], axis=1)\n",
        "\n",
        "    # Handling infinite and nan values.\n",
        "    x_bruteforce.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    x_bruteforce.fillna(x_bruteforce.mean(), inplace=True)\n",
        "\n",
        "    # Doing feature scaling.\n",
        "    scaler = StandardScaler()\n",
        "    x_bruteforce = scaler.fit_transform(x_bruteforce)\n",
        "    x_bruteforce = pd.DataFrame(x_bruteforce)\n",
        "    column_list = column_list.drop([column_list[0], column_list[-1]])\n",
        "    x_bruteforce.columns = column_list\n",
        "\n",
        "    # Label encoding.\n",
        "    le = LabelEncoder()\n",
        "    y_bruteforce = le.fit_transform(y_bruteforce)\n",
        "\n",
        "    # Train dataset.\n",
        "    x_train_bruteforce = x_bruteforce[:int(0.8 * (len(x_bruteforce)))]\n",
        "    y_train_bruteforce = y_bruteforce[:int(0.8 * (len(y_bruteforce)))]\n",
        "\n",
        "    # Test dataset.\n",
        "    x_test_bruteforce = x_bruteforce[int(0.8 * (len(x_bruteforce))):]\n",
        "    y_test_bruteforce = y_bruteforce[int(0.8 * (len(x_bruteforce))):]\n",
        "\n",
        "    return x_train_bruteforce, y_train_bruteforce, x_test_bruteforce, y_test_bruteforce\n",
        "\n",
        "\n",
        "def get_cic_data(data):\n",
        "    file = open('final_data.txt', 'rb')\n",
        "    data = pickle.load(file)\n",
        "    x_train, y_train, x_test, y_test = get_data(data)\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def divide_without_label(parts, X_train_full, y_train_full):\n",
        "    each_part_number = int(len(X_train_full) / parts)\n",
        "    list_x_train = []\n",
        "    list_y_train = []\n",
        "\n",
        "    number_list = []\n",
        "    number_list.append(0)\n",
        "    for x in range(1, parts + 1):\n",
        "        number_list.append(each_part_number * x)\n",
        "\n",
        "    for x in range(0, parts):\n",
        "        data_x = X_train_full[number_list[x]:number_list[x + 1]]\n",
        "        data_y = y_train_full[number_list[x]:number_list[x + 1]]\n",
        "        list_x_train.append(data_x)\n",
        "        list_y_train.append(data_y)\n",
        "\n",
        "    return list_x_train, list_y_train\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = merge_data()\n",
        "    x_train, y_train, x_valid, y_valid = get_cic_data(data)\n",
        "    x_data, y_data = divide_without_label(11, x_train, y_train)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}