{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASXXq43OAKKM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from tensorflow import keras\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Client:\n",
        "    def __init__(self, dataset_x, dataset_y, epoch_number, learning_rate,\n",
        "                 weights, batch, features):\n",
        "        self.dataset_x = dataset_x\n",
        "        self.dataset_y = dataset_y\n",
        "        self.epoch_number = epoch_number\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.batch = batch\n",
        "        self.features = features\n",
        "\n",
        "    def train(self):\n",
        "        model = keras.models.Sequential([\n",
        "            keras.layers.Flatten(input_shape=[\n",
        "                self.features,\n",
        "            ]),\n",
        "            keras.layers.Dense(200, activation='tanh'),\n",
        "            keras.layers.Dense(100, activation='tanh'),\n",
        "            keras.layers.Dense(12, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        #setting weight of the model\n",
        "        model.set_weights(self.weights)\n",
        "\n",
        "        model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        history = model.fit(self.dataset_x,\n",
        "                            self.dataset_y,\n",
        "                            epochs=self.epoch_number,\n",
        "                            batch_size=self.batch)\n",
        "\n",
        "        #getting the final_weight\n",
        "        output_weight = model.get_weights()\n",
        "        return output_weight"
      ],
      "metadata": {
        "id": "jkM1e3fNDRxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/drive/MyDrive/Dataset/x_data\", 'rb') x_data = pickle.load(file)\n",
        "file = open(\"/content/drive/MyDrive/Dataset/y_data\", 'rb') y_data = pickle.load(file)\n",
        "file = open(\"/content/drive/MyDrive/Dataset/x_valid\", 'rb') x_valid = pickle.load(file)\n",
        "file = open(\"/content/drive/MyDrive/Dataset/y_valid\", 'rb') y_valid = pickle.load(file)"
      ],
      "metadata": {
        "id": "Wd1EkTYmD7Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(x_data, y_data, x_valid):\n",
        "    arr = [0] * 77\n",
        "    fvalue_Best = SelectKBest(f_classif, k=35)\n",
        "    x = np.array(x_data)\n",
        "    y = np.array(y_data)\n",
        "\n",
        "    for idx in range(len(x)):\n",
        "        X_kbest = fvalue_Best.fit_transform(x[idx], y[idx])\n",
        "        i, j = 0, 0\n",
        "        while (j < 78 and i < 35):\n",
        "            if (eval(str(X_kbest[0][i])) == eval(str(x[idx][0][j]))):\n",
        "                arr[j] += 1\n",
        "                i += 1\n",
        "            j += 1\n",
        "\n",
        "    temp_arr = []\n",
        "    for idx in range(len(arr)):\n",
        "        temp_arr.append((arr[idx], idx))\n",
        "    temp_arr.sort()\n",
        "    temp_arr.reverse()\n",
        "\n",
        "    feature_count = 20\n",
        "    final_ft = []\n",
        "    for idx in range(len(temp_arr)):\n",
        "        if idx < feature_count:\n",
        "            final_ft.append(temp_arr[idx][1])\n",
        "        else:\n",
        "            if (temp_arr[idx][0] == temp_arr[idx - 1][0]):\n",
        "                final_ft.append(temp_arr[idx][1])\n",
        "            else:\n",
        "                break\n",
        "    final_ft.sort()\n",
        "\n",
        "    # Selecting the features from x_data.\n",
        "    x_data = np.array(x_data)\n",
        "    x_data = x_data[:, :, final_ft]\n",
        "\n",
        "    # Selecting the features from x_valid.\n",
        "    x_valid = np.array(x_valid)\n",
        "    x_valid = x_valid[:, final_ft]\n",
        "    # print(final_ft)\n",
        "    return x_data, x_valid, len(final_ft)"
      ],
      "metadata": {
        "id": "5OGK9uJED-I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(features):\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[\n",
        "            features,\n",
        "        ]),\n",
        "        keras.layers.Dense(200, activation='tanh'),\n",
        "        keras.layers.Dense(100, activation='tanh'),\n",
        "        keras.layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8_j1S2blEUTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for averaging.\n",
        "def model_average(client_weights):\n",
        "    average_weight_list = []\n",
        "    for index1 in range(len(client_weights[0])):\n",
        "        layer_weights = []\n",
        "        for index2 in range(len(client_weights)):\n",
        "            weights = client_weights[index2][index1]\n",
        "            layer_weights.append(weights)\n",
        "        average_weight = np.mean(np.array([x for x in layer_weights]), axis=0)\n",
        "        average_weight_list.append(average_weight)\n",
        "    return average_weight_list"
      ],
      "metadata": {
        "id": "IHgYCFFCFB0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(features):\n",
        "  model = get_model(features)\n",
        "  weight = model.get_weights()\n",
        "  return weight"
      ],
      "metadata": {
        "id": "JU24wvuqFrGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_server(training_rounds, epoch, batch, learning_rate, x_data, x_valid,\n",
        "                 features):\n",
        "    # temp_variable\n",
        "    # training_rounds=2\n",
        "    # epoch=5\n",
        "    # batch=128\n",
        "\n",
        "    accuracy_list = []\n",
        "    client_weight_for_sending = []\n",
        "\n",
        "    for index1 in range(1, training_rounds):\n",
        "        print('Training for round ', index1, 'started')\n",
        "        client_weights_tobe_averaged = []\n",
        "        for index in range(len(y_data)):\n",
        "            print('-------Client-------', index)\n",
        "            if index1 == 1:\n",
        "                print(\n",
        "                    'Sharing Initial Global Model with Random Weight Initialization'\n",
        "                )\n",
        "                initial_weight = create_model(features)\n",
        "                client = Client(x_data[index], y_data[index], epoch,\n",
        "                                learning_rate, initial_weight, batch, features)\n",
        "                weight = client.train()\n",
        "                client_weights_tobe_averaged.append(weight)\n",
        "            else:\n",
        "                client = Client(x_data[index], y_data[index], epoch,\n",
        "                                learning_rate,\n",
        "                                client_weight_for_sending[index1 - 2], batch,\n",
        "                                features)\n",
        "                weight = client.train()\n",
        "                client_weights_tobe_averaged.append(weight)\n",
        "\n",
        "        # Calculating the avearge weight from all the clients.\n",
        "        client_average_weight = model_average(client_weights_tobe_averaged)\n",
        "        client_weight_for_sending.append(client_average_weight)\n",
        "\n",
        "        # Validating the model with avearge weight.\n",
        "        model = get_model(features)\n",
        "\n",
        "        model.set_weights(client_average_weight)\n",
        "        model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.SGD(lr=learning_rate),\n",
        "                      metrics=['accuracy'])\n",
        "        # print(x_valid)\n",
        "        result = model.evaluate(x_valid, y_valid)\n",
        "        accuracy = result[1]\n",
        "        print('#######-----Acccuracy for round ', index1, 'is ', accuracy,\n",
        "              ' ------########')\n",
        "        accuracy_list.append(accuracy)\n",
        "        accuracy_list_global.append(accuracy)\n",
        "\n",
        "        # print(\"HEEEEEEEEEEEEEEEELLLLLLLLLLLOOOOOOOOOOOOOOO\")\n",
        "        for i in range(12):\n",
        "            temp_y_valid = []\n",
        "            temp_x_valid = []\n",
        "            for ind, x in enumerate(y_valid):\n",
        "                if x == i:\n",
        "                    temp_y_valid.append(x)\n",
        "                    temp_x_valid.append(list(x_valid[ind]))\n",
        "            temp_y_valid = np.array(temp_y_valid)\n",
        "            temp_x_valid = np.array(temp_x_valid)\n",
        "            result = model.evaluate(temp_x_valid, temp_y_valid)\n",
        "            accuracy = result[1]\n",
        "            print('#######-----Acccuracy for attack ', i, 'is ', accuracy,\n",
        "                  ' ------########')\n",
        "\n",
        "    return accuracy_list, client_weight_for_sending"
      ],
      "metadata": {
        "id": "aVc1bIv2FtJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main(x_data, x_valid, features):\n",
        "  start = time.time()\n",
        "  training_accuracy, weights = train_server(100, 5, 64, 0.01, x_data, x_valid, features)\n",
        "  end = time.time()\n",
        "  print('TOTAL TIME = ', end - start)\n"
      ],
      "metadata": {
        "id": "9axtkf_9HOVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  x_data, x_valid, features = feature_selection(x_data, y_data, x_valid)\n",
        "  # features = 77\n",
        "  train_main(x_data, x_valid, features)\n",
        "  pass\n",
        "  print(accuracy_list_global)"
      ],
      "metadata": {
        "id": "v7bDTm7kHY8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3BIvRoKpHkhk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}